{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 09 MINIST_DNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogerallen741/PyTorch-Learning/blob/master/Lecture_09_MINIST_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j34sds1utdMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from torch import nn, optim, cuda\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbO3CU8OvkSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training settings\n",
        "use_cuda = False\n",
        "batch_size = 64\n",
        "lr_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O32JDkLsv8-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFn8rsnIuKlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.l1 = nn.Linear(784,520)\n",
        "    self.l2 = nn.Linear(520,320)\n",
        "    self.l3 = nn.Linear(320,240)\n",
        "    self.l4 = nn.Linear(240,120)\n",
        "    self.l5 = nn.Linear(120,10)\n",
        "  def forward(self, x):\n",
        "    #Flatten the data(n,1,28,28) -> (n,784)\n",
        "    x = x.view(-1,784)\n",
        "    x = nn.functional .relu(self.l1(x))\n",
        "    x = nn.functional .relu(self.l2(x))\n",
        "    x = nn.functional .relu(self.l3(x))\n",
        "    x = nn.functional .relu(self.l4(x))\n",
        "    return nn.functional .relu(self.l5(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmyWAyTJx03C",
        "colab_type": "code",
        "outputId": "71659c96-74ea-4499-8374-40585020d4d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = Net()\n",
        "\n",
        "if use_cuda and cuda.is_available():\n",
        "  device = 'cuda' \n",
        "  model.cuda()\n",
        "else:\n",
        "  device = 'cpu'\n",
        "print(f'Training MNIST　Model on {device}\\n{\"=\" * 44}')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr_rate, momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MNIST　Model on cpu\n",
            "============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUtLitqHyNIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data.to(device)), Variable(target.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMYEM4qazhrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "    data, target = Variable(data.to(device)), Variable(target.to(device))\n",
        "    output = model(data)\n",
        "    # sum up batch loss \n",
        "    test_loss += criterion(output, target).item()   \n",
        "    # get the index of the max\n",
        "    pred = output.data.max(1, keepdim=True)[1]\n",
        "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)  \n",
        "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
        "          f'({100. * correct / len(test_loader.dataset):.0f}%)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNhYVLpM0gu9",
        "colab_type": "code",
        "outputId": "25f8d1c8-d8f0-4996-8919-43689b1cda3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    since = time.time()\n",
        "    for epoch in range(1, 5):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        train(epoch)\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "        \n",
        "        test()\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
        "\n",
        "    m, s = divmod(time.time() - since, 60)\n",
        "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.301999\n",
            "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.302825\n",
            "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.308883\n",
            "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.298752\n",
            "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.300549\n",
            "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.305279\n",
            "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.300711\n",
            "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.308017\n",
            "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.303407\n",
            "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.300365\n",
            "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.306388\n",
            "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.305733\n",
            "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.303358\n",
            "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.300462\n",
            "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.293014\n",
            "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.309348\n",
            "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.296865\n",
            "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.297709\n",
            "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.293621\n",
            "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.301646\n",
            "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.296474\n",
            "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.289521\n",
            "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.301711\n",
            "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.297656\n",
            "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.302771\n",
            "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.293006\n",
            "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.295466\n",
            "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.293933\n",
            "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.294119\n",
            "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.290265\n",
            "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.299970\n",
            "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.289557\n",
            "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.284762\n",
            "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.295230\n",
            "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.291229\n",
            "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.285408\n",
            "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.284187\n",
            "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.291530\n",
            "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.284883\n",
            "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.289145\n",
            "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.282874\n",
            "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.286030\n",
            "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.276364\n",
            "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.271263\n",
            "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.288304\n",
            "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.287008\n",
            "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.274361\n",
            "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.275754\n",
            "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.296995\n",
            "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.288931\n",
            "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.275506\n",
            "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.284427\n",
            "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.281327\n",
            "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.276991\n",
            "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.281255\n",
            "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.278738\n",
            "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.270671\n",
            "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.270423\n",
            "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.266058\n",
            "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.260353\n",
            "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.259826\n",
            "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.246326\n",
            "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.246477\n",
            "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.262734\n",
            "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.238495\n",
            "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.239227\n",
            "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.234679\n",
            "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.255761\n",
            "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.215304\n",
            "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.241643\n",
            "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.227397\n",
            "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.220478\n",
            "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.211299\n",
            "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.184147\n",
            "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.216437\n",
            "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.180407\n",
            "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.195150\n",
            "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.219432\n",
            "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.175069\n",
            "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 2.153790\n",
            "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 2.103883\n",
            "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 2.170794\n",
            "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 2.150690\n",
            "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 2.156857\n",
            "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 2.077076\n",
            "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 2.041345\n",
            "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 2.084279\n",
            "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 2.060833\n",
            "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 2.077492\n",
            "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 2.087205\n",
            "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 2.021638\n",
            "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 1.950620\n",
            "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.973876\n",
            "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 1.946935\n",
            "Training time: 0m 14s\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 31/10000 (0%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 61/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 88/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 112/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 136/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 166/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 187/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 208/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 230/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 253/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 287/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 314/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 337/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 365/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 389/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 420/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 439/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 462/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 494/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 514/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 535/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 562/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 581/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 605/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 632/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 653/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 677/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 706/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 737/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 761/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 784/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 812/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 833/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 854/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 875/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 899/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 932/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 955/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 983/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1002/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1027/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1051/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1080/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1102/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1133/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1152/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1179/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1209/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1234/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1261/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1287/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1317/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1345/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1377/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1394/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1416/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1448/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1476/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1499/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1518/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1540/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1558/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1589/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1621/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1643/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1668/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1688/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1711/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1729/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1753/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1778/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1806/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1832/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1858/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1888/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1910/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1936/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1958/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1985/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2013/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2040/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2062/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2093/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2122/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2145/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2177/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2207/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2228/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2259/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2284/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2311/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2339/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2369/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2401/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2428/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2463/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2487/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2514/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2543/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2572/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2596/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2616/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2645/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2667/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2692/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2722/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2750/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2771/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2800/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2820/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2847/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2877/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2909/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2934/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2964/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2993/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3021/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3050/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3078/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3106/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3136/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3162/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3187/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3218/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3241/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3269/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3301/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3325/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3350/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3371/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3397/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3424/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3450/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3483/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3509/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3532/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3559/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3586/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3614/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3635/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3666/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3697/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3724/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3753/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3783/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3813/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3842/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3876/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3903/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3930/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3963/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3984/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 4006/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 4034/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 4059/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 4091/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 4097/10000 (41%)\n",
            "Testing time: 0m 15s\n",
            "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 2.016911\n",
            "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.971263\n",
            "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.930555\n",
            "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.780983\n",
            "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.803103\n",
            "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.742537\n",
            "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 1.997491\n",
            "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 1.834563\n",
            "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 1.865065\n",
            "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 1.697459\n",
            "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 1.787668\n",
            "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 1.328046\n",
            "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 1.592126\n",
            "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 1.732790\n",
            "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 1.813147\n",
            "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 1.635928\n",
            "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 1.343818\n",
            "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 1.594036\n",
            "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 1.528471\n",
            "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 1.623369\n",
            "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 1.488541\n",
            "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 1.410270\n",
            "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 1.329812\n",
            "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 1.092331\n",
            "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 1.469034\n",
            "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 1.059398\n",
            "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 1.290777\n",
            "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 1.224031\n",
            "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 1.051187\n",
            "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 1.127431\n",
            "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 1.024658\n",
            "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 1.209588\n",
            "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 1.611140\n",
            "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 1.073745\n",
            "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 1.037046\n",
            "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.949271\n",
            "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 1.391741\n",
            "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 1.017956\n",
            "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 1.164859\n",
            "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.985224\n",
            "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.915762\n",
            "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.946288\n",
            "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 1.072059\n",
            "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 1.032228\n",
            "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.809335\n",
            "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.852484\n",
            "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 1.066841\n",
            "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.787157\n",
            "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 1.184771\n",
            "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.980288\n",
            "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.896958\n",
            "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.655272\n",
            "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.781763\n",
            "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.808844\n",
            "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.982904\n",
            "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.892429\n",
            "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.940233\n",
            "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.844707\n",
            "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.931816\n",
            "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.929835\n",
            "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 1.054614\n",
            "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.768220\n",
            "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.745828\n",
            "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.611563\n",
            "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.823516\n",
            "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.887953\n",
            "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 1.023512\n",
            "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.961742\n",
            "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.864737\n",
            "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 1.010057\n",
            "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.833450\n",
            "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.854685\n",
            "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 1.031324\n",
            "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.564118\n",
            "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.655904\n",
            "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.629922\n",
            "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.696448\n",
            "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.809774\n",
            "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.484851\n",
            "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.923070\n",
            "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.736121\n",
            "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.777255\n",
            "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.710820\n",
            "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.690573\n",
            "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.800226\n",
            "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.812114\n",
            "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.757415\n",
            "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.833577\n",
            "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.950792\n",
            "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.730810\n",
            "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.672417\n",
            "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.959629\n",
            "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.952551\n",
            "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.811661\n",
            "Training time: 0m 14s\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 48/10000 (0%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 96/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 154/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 201/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 251/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 298/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 350/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 392/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 436/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 480/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 529/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 580/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 634/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 683/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 730/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 781/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 832/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 879/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 932/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 978/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1021/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1071/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1112/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1161/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1212/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1257/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1308/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1350/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1397/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1447/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1496/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1548/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1596/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1648/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1694/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1744/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1790/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1835/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1882/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1929/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1976/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2026/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2075/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2128/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2175/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2223/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2266/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2323/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2377/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2428/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2487/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2542/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2594/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2646/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2692/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2739/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2791/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2842/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2891/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2931/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2973/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3024/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3069/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3118/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3169/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3216/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3258/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3297/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3349/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3393/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3444/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3490/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3541/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3591/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3642/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3689/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3741/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3788/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3836/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3884/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3937/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3986/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4040/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4097/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4153/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4212/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4268/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4315/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4368/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4418/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4471/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4520/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4569/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4621/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4668/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4720/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4774/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4830/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4887/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4940/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4986/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5038/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5087/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5131/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5183/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5234/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5287/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5341/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5394/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5447/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5501/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5555/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5609/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5660/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5711/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5764/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5813/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5860/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5911/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5961/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6015/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6068/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6107/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6155/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6210/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6259/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6309/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6365/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6421/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6470/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6521/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6576/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6624/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6677/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6733/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6789/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6847/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6904/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6962/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7013/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7061/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7108/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7166/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7218/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7269/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7324/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7382/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7431/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7479/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7528/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7579/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7625/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7670/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7718/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7765/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7815/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7827/10000 (78%)\n",
            "Testing time: 0m 15s\n",
            "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.666199\n",
            "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.594764\n",
            "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.756354\n",
            "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.524016\n",
            "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.662583\n",
            "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.478529\n",
            "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.716934\n",
            "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.418967\n",
            "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.803180\n",
            "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.696156\n",
            "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.652266\n",
            "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.631312\n",
            "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.514438\n",
            "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.587054\n",
            "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.648488\n",
            "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.720369\n",
            "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.824637\n",
            "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.734792\n",
            "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.597743\n",
            "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.873091\n",
            "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.610979\n",
            "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.621669\n",
            "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.730124\n",
            "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.601567\n",
            "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.442439\n",
            "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.589536\n",
            "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.628253\n",
            "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.725742\n",
            "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.550221\n",
            "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.535038\n",
            "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.696987\n",
            "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.512133\n",
            "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.766878\n",
            "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.689669\n",
            "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.551732\n",
            "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.651037\n",
            "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.556478\n",
            "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.570912\n",
            "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.393261\n",
            "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.634145\n",
            "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.639827\n",
            "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.605609\n",
            "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.595362\n",
            "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.869141\n",
            "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.662123\n",
            "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.735724\n",
            "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.655782\n",
            "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.583786\n",
            "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.927917\n",
            "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.679132\n",
            "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.837348\n",
            "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.579949\n",
            "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.854016\n",
            "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.537900\n",
            "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.537820\n",
            "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.582559\n",
            "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.476173\n",
            "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.755917\n",
            "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.265633\n",
            "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.530217\n",
            "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.622706\n",
            "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.545208\n",
            "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.632214\n",
            "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.609279\n",
            "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.725970\n",
            "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.591816\n",
            "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.486606\n",
            "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.592796\n",
            "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.529424\n",
            "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.467381\n",
            "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.527973\n",
            "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.305815\n",
            "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.474374\n",
            "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.580211\n",
            "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.678615\n",
            "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.637456\n",
            "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.365597\n",
            "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.717399\n",
            "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.466241\n",
            "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.421406\n",
            "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.502509\n",
            "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.596786\n",
            "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.436793\n",
            "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.518535\n",
            "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.546747\n",
            "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.524637\n",
            "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.569592\n",
            "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.599686\n",
            "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.410856\n",
            "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.468970\n",
            "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.559312\n",
            "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.378724\n",
            "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.605455\n",
            "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.435547\n",
            "Training time: 0m 14s\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 57/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 111/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 170/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 222/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 280/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 335/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 390/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 439/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 491/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 543/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 600/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 657/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 715/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 769/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 822/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 877/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 931/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 983/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1037/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1086/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1133/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1190/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1240/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1291/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1346/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1399/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1454/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1503/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1555/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1605/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1657/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1712/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1767/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1824/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1878/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1932/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1985/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2037/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2091/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2143/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2194/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2248/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2301/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2357/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2411/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2460/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2510/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2568/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2626/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2682/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2743/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2801/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2857/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2912/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2965/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3015/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3073/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3130/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3186/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3230/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3275/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3327/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3379/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3433/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3487/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3540/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3587/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3634/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3689/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3738/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3790/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3844/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3902/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3956/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4013/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4067/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4121/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4174/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4228/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4285/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4341/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4399/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4455/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4516/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4577/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4639/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4699/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4757/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4813/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4869/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4929/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4983/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5040/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5095/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5150/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5208/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5266/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5328/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5389/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5445/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5501/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5558/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5610/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5659/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5715/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5765/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5819/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5874/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5932/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5992/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6051/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6112/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6171/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6229/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6288/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6345/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6400/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6454/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6510/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6570/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6627/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6681/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6728/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6781/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6837/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6893/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6945/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7004/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7063/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7117/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7171/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7230/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7286/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7345/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7405/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7466/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7526/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7584/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7645/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7706/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7760/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7812/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7871/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7929/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7987/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8046/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8105/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8158/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8214/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8267/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8321/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8376/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8425/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8479/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8531/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8586/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8600/10000 (86%)\n",
            "Testing time: 0m 15s\n",
            "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.639847\n",
            "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.481276\n",
            "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.444276\n",
            "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.672048\n",
            "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.575165\n",
            "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.533359\n",
            "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.595193\n",
            "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.722594\n",
            "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.458774\n",
            "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.302394\n",
            "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.534285\n",
            "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.383188\n",
            "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.766744\n",
            "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.679758\n",
            "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.731945\n",
            "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.345985\n",
            "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.408422\n",
            "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.488206\n",
            "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.454949\n",
            "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.554985\n",
            "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.603854\n",
            "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.432837\n",
            "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.843227\n",
            "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.524911\n",
            "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.395364\n",
            "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.426648\n",
            "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.416282\n",
            "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.506348\n",
            "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.653986\n",
            "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.732565\n",
            "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.426460\n",
            "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.366051\n",
            "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.437464\n",
            "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.591797\n",
            "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.412653\n",
            "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.313917\n",
            "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.466710\n",
            "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.439937\n",
            "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.712403\n",
            "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.330173\n",
            "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.724408\n",
            "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.385237\n",
            "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.298848\n",
            "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.299147\n",
            "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.466500\n",
            "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.481746\n",
            "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.434109\n",
            "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.510479\n",
            "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.320903\n",
            "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.383611\n",
            "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.489665\n",
            "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.419545\n",
            "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.350313\n",
            "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.484682\n",
            "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.376184\n",
            "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.370140\n",
            "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.385268\n",
            "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.717084\n",
            "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.619948\n",
            "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.443212\n",
            "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.403377\n",
            "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.616781\n",
            "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.417907\n",
            "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.438350\n",
            "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.780384\n",
            "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.400160\n",
            "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.480474\n",
            "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.534815\n",
            "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.453473\n",
            "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.599057\n",
            "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.412509\n",
            "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.355137\n",
            "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.545430\n",
            "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.368412\n",
            "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.292309\n",
            "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.739929\n",
            "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.427070\n",
            "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.491042\n",
            "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.442646\n",
            "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.514041\n",
            "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.326582\n",
            "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.561387\n",
            "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.323101\n",
            "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.343722\n",
            "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.570144\n",
            "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.679737\n",
            "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.530908\n",
            "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.411099\n",
            "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.446241\n",
            "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.513937\n",
            "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.555316\n",
            "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.378196\n",
            "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.371531\n",
            "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.543521\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 58/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 114/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 172/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 227/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 285/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 339/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 390/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 441/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 501/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 555/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 615/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 669/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 728/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 784/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 839/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 895/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 952/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1009/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1063/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1115/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1171/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1227/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1277/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1332/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1387/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1439/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1494/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1548/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1601/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1655/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1709/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1763/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1818/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1877/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1930/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1985/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2040/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2090/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2142/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2193/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2247/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2304/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2358/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2415/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2471/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2524/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2579/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2637/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2695/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2752/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2809/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2867/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2923/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2978/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3031/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3085/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3139/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3195/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3252/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3301/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3348/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3402/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3452/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3507/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3557/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3609/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3663/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3713/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3766/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3816/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3867/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3926/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3980/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4035/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4095/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4148/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4201/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4249/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4308/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4367/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4423/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4483/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4540/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4600/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4660/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4719/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4779/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4839/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4893/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4947/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5006/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5063/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5119/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5169/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5224/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5282/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5341/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5402/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5465/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5524/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5582/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5643/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5699/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5748/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5806/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5862/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5918/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5974/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6032/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6090/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6147/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6203/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6257/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6310/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6370/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6432/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6486/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6541/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6599/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6658/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6717/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6773/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6822/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6880/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6938/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6994/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7048/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7107/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7167/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7224/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7280/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7338/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7395/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7453/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7515/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7574/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7635/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7695/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7757/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7815/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7869/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7921/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7980/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8035/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8090/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8148/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8208/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8263/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8319/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8374/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8430/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8482/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8529/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8583/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8636/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8694/10000 (87%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8707/10000 (87%)\n",
            "Testing time: 0m 15s\n",
            "Total Time: 1m 1s\n",
            "Model was trained on cpu!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}