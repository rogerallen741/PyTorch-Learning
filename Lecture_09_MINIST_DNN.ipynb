{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 09 MINIST_DNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogerallen741/PyTorch-Learning/blob/master/Lecture_09_MINIST_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j34sds1utdMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from torch import nn, optim, cuda\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbO3CU8OvkSe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f2f6e7ca-8056-47ae-9dfa-69c15b37421f"
      },
      "source": [
        "#Training settings\n",
        "batch_size = 64\n",
        "lr_rate = 0.01\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'Training MNIST　Model on {device}\\n{\"=\" * 44}')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MNIST　Model on cpu\n",
            "============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O32JDkLsv8-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFn8rsnIuKlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.l1 = nn.Linear(784,520)\n",
        "    self.l2 = nn.Linear(520,320)\n",
        "    self.l3 = nn.Linear(320,240)\n",
        "    self.l4 = nn.Linear(240,120)\n",
        "    self.l5 = nn.Linear(120,10)\n",
        "  def forward(self, x):\n",
        "    #Flatten the data(n,1,28,28) -> (n,784)\n",
        "    x = x.view(-1,784)\n",
        "    x = nn.functional .relu(self.l1(x))\n",
        "    x = nn.functional .relu(self.l2(x))\n",
        "    x = nn.functional .relu(self.l3(x))\n",
        "    x = nn.functional .relu(self.l4(x))\n",
        "    return nn.functional .relu(self.l5(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmyWAyTJx03C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr_rate, momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUtLitqHyNIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMYEM4qazhrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    # sum up batch loss \n",
        "    test_loss += criterion(output, target).item()   \n",
        "    # get the index of the max\n",
        "    pred = output.data.max(1, keepdim=True)[1]\n",
        "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)  \n",
        "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
        "          f'({100. * correct / len(test_loader.dataset):.0f}%)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNhYVLpM0gu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac01f6a3-ffa2-4c3b-8dfe-3424470cfb5f"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    since = time.time()\n",
        "    for epoch in range(1, 10):\n",
        "        epoch_start = time.time()\n",
        "        train(epoch)\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "        test()\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
        "\n",
        "    m, s = divmod(time.time() - since, 60)\n",
        "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.301438\n",
            "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.295333\n",
            "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.291690\n",
            "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.298944\n",
            "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.295944\n",
            "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.300766\n",
            "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.302464\n",
            "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.306267\n",
            "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.294696\n",
            "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.298206\n",
            "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.301266\n",
            "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.304130\n",
            "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.297521\n",
            "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.293087\n",
            "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.294220\n",
            "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.297257\n",
            "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.297778\n",
            "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.305979\n",
            "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.294252\n",
            "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.294954\n",
            "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.289902\n",
            "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.294236\n",
            "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.299207\n",
            "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.296005\n",
            "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.294621\n",
            "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.291993\n",
            "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.304179\n",
            "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.291336\n",
            "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.295567\n",
            "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.296936\n",
            "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.291178\n",
            "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.299470\n",
            "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.288711\n",
            "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.302135\n",
            "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.282396\n",
            "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.293485\n",
            "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.296841\n",
            "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.293568\n",
            "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.285810\n",
            "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.282655\n",
            "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.286106\n",
            "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.290286\n",
            "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.295372\n",
            "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.283985\n",
            "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.278995\n",
            "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.286189\n",
            "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.287305\n",
            "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.287141\n",
            "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.274438\n",
            "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.281881\n",
            "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.279272\n",
            "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.285616\n",
            "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.293317\n",
            "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.275604\n",
            "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.272200\n",
            "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.271959\n",
            "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.259974\n",
            "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.255410\n",
            "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.282482\n",
            "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.260115\n",
            "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.280580\n",
            "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.266703\n",
            "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.270064\n",
            "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.252756\n",
            "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.276782\n",
            "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.272588\n",
            "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.252888\n",
            "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.257047\n",
            "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.244344\n",
            "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.261225\n",
            "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.249288\n",
            "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.240792\n",
            "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.237856\n",
            "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.217538\n",
            "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.213801\n",
            "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.194673\n",
            "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.224192\n",
            "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.201097\n",
            "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.185600\n",
            "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 2.155932\n",
            "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 2.197402\n",
            "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 2.170413\n",
            "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 2.176373\n",
            "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 2.123777\n",
            "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 2.227961\n",
            "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 2.126482\n",
            "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 2.093838\n",
            "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 2.139677\n",
            "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 2.072454\n",
            "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 2.076177\n",
            "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 2.221853\n",
            "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 2.179008\n",
            "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.988915\n",
            "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 2.080706\n",
            "Training time: 0m 16s\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 23/10000 (0%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 38/10000 (0%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 63/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 80/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 101/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 122/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 140/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 156/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 170/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 189/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 210/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 232/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 249/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 268/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 286/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 311/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 329/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 343/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 366/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 383/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 399/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 421/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 436/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 455/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 475/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 491/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 511/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 531/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 550/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 571/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 586/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 604/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 621/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 637/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 658/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 681/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 704/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 726/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 740/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 756/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 774/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 792/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 815/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 833/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 851/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 865/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 883/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 903/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 920/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 939/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 962/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 988/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1009/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1031/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1046/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1059/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1088/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1109/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1126/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1143/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1163/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1175/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1197/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1230/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1254/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1274/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1288/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1305/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1322/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1336/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1356/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1373/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1397/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1418/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1442/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1460/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1478/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1499/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1522/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1543/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1566/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1580/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1600/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1625/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1641/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1666/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1695/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1710/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1734/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1750/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1774/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1798/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1820/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1847/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1864/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1888/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1906/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1929/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1956/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 1982/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2010/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2033/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2050/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2073/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2095/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2117/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2140/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2161/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2187/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2204/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2225/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2244/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2272/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2293/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2316/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2338/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2356/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2370/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2397/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2420/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2441/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2467/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2491/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2515/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2537/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2560/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2583/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2604/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2629/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2649/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2669/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2694/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2713/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2737/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2758/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2780/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2808/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2826/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2852/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2870/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2894/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2916/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2939/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2962/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2985/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3018/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3042/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3066/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3084/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3107/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3130/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3152/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3171/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3196/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3218/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3240/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 3245/10000 (32%)\n",
            "Testing time: 0m 17s\n",
            "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 2.006051\n",
            "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.993889\n",
            "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 2.113418\n",
            "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.973655\n",
            "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 2.035285\n",
            "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 2.006170\n",
            "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 2.034446\n",
            "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 2.019134\n",
            "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 2.094783\n",
            "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 2.039410\n",
            "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 1.941790\n",
            "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 1.954334\n",
            "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 1.887540\n",
            "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 1.904584\n",
            "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 1.722809\n",
            "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 1.876779\n",
            "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 1.884854\n",
            "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 1.695679\n",
            "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 1.930990\n",
            "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 1.898395\n",
            "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 1.786748\n",
            "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 1.752796\n",
            "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 1.772678\n",
            "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 1.760040\n",
            "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 1.399033\n",
            "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 1.530452\n",
            "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 1.496918\n",
            "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 1.552321\n",
            "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 1.526028\n",
            "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 1.350501\n",
            "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 1.510463\n",
            "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 1.376312\n",
            "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 1.229362\n",
            "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 1.539777\n",
            "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 1.259385\n",
            "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 1.440748\n",
            "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 1.428020\n",
            "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 1.329176\n",
            "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 1.380875\n",
            "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 1.483556\n",
            "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 1.332492\n",
            "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 1.227175\n",
            "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 1.165149\n",
            "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 1.321499\n",
            "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 1.131481\n",
            "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 1.185811\n",
            "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 1.141312\n",
            "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 1.202883\n",
            "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 1.135364\n",
            "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.834675\n",
            "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 1.019451\n",
            "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 1.149964\n",
            "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 1.058640\n",
            "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 1.175956\n",
            "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 1.054824\n",
            "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.805783\n",
            "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 1.239404\n",
            "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.952480\n",
            "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 1.002440\n",
            "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.865339\n",
            "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.890241\n",
            "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.961105\n",
            "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.974632\n",
            "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.908873\n",
            "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.966480\n",
            "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.845251\n",
            "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 1.100759\n",
            "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 1.076203\n",
            "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.736907\n",
            "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.876953\n",
            "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 1.083170\n",
            "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 1.047539\n",
            "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.992220\n",
            "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.847242\n",
            "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 1.318833\n",
            "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 1.029584\n",
            "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.802791\n",
            "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 1.014727\n",
            "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.901056\n",
            "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.925245\n",
            "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.857431\n",
            "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.929420\n",
            "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.826056\n",
            "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.672337\n",
            "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.977213\n",
            "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.733323\n",
            "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.886243\n",
            "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.809613\n",
            "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 1.066254\n",
            "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.923602\n",
            "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 1.016281\n",
            "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.842428\n",
            "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 1.063904\n",
            "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.864911\n",
            "Training time: 0m 15s\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 50/10000 (0%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 97/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 142/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 185/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 233/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 275/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 326/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 369/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 412/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 456/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 503/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 547/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 590/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 637/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 680/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 731/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 774/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 813/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 859/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 896/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 939/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 989/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1034/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1076/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1126/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1170/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1217/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1256/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1302/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1350/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1393/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1431/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1472/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1518/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1563/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1611/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1658/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1703/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1756/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1793/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1832/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1872/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1919/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1959/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2008/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2050/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2090/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2140/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2176/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2223/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2277/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2323/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2371/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2415/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2462/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2504/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2553/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2604/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2643/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0002, Accuracy: 2677/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2726/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2767/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2813/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2861/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2913/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2960/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2998/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3039/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3087/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3133/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3177/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3224/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3272/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3321/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3368/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3411/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3454/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3500/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3553/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3605/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3653/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3694/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3745/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3794/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3848/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3899/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3952/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3997/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4049/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4095/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4145/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4188/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4233/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4283/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4330/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4378/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4424/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4476/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4526/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4574/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4626/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4672/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4714/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4760/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4813/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4858/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4907/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4953/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5002/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5051/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5105/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5154/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5205/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5252/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5302/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5347/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5388/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5437/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5487/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5533/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5586/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5638/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5680/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5727/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5771/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5817/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5867/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5914/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5964/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6012/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6058/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6106/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6152/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6204/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6257/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6304/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6357/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6409/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6458/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6511/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6559/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6607/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6657/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6704/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6751/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6801/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6852/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6903/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6949/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6995/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7042/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7088/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7128/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7173/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7219/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7270/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7280/10000 (73%)\n",
            "Testing time: 0m 16s\n",
            "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.857914\n",
            "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.923396\n",
            "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.765226\n",
            "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.941917\n",
            "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.972014\n",
            "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.681698\n",
            "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.747233\n",
            "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 1.068511\n",
            "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.755747\n",
            "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 1.257877\n",
            "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.722858\n",
            "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.822897\n",
            "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.727515\n",
            "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 1.012746\n",
            "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 1.132039\n",
            "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.629697\n",
            "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.947918\n",
            "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.634159\n",
            "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.650684\n",
            "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.826600\n",
            "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.590651\n",
            "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.605262\n",
            "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 1.034859\n",
            "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 1.175567\n",
            "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.849536\n",
            "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.940279\n",
            "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 1.152356\n",
            "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.967435\n",
            "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.909366\n",
            "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.690042\n",
            "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.745167\n",
            "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.792161\n",
            "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.716717\n",
            "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 1.055546\n",
            "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.876242\n",
            "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.763836\n",
            "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.663822\n",
            "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.889966\n",
            "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.788477\n",
            "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.755959\n",
            "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.857953\n",
            "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.742443\n",
            "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.743091\n",
            "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.968992\n",
            "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.625430\n",
            "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.932959\n",
            "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.530905\n",
            "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.697769\n",
            "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.729547\n",
            "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.745542\n",
            "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.728411\n",
            "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.773142\n",
            "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.710776\n",
            "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.856724\n",
            "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.775812\n",
            "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.847726\n",
            "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.676866\n",
            "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.499233\n",
            "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.827106\n",
            "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.762422\n",
            "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.813052\n",
            "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 1.131066\n",
            "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.704378\n",
            "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.853500\n",
            "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.730112\n",
            "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.915652\n",
            "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.740729\n",
            "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.624143\n",
            "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.821642\n",
            "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.661108\n",
            "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.709587\n",
            "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.837269\n",
            "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.567937\n",
            "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.707455\n",
            "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.634026\n",
            "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.526258\n",
            "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.440623\n",
            "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.591147\n",
            "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.769191\n",
            "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 1.182566\n",
            "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.616180\n",
            "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.791947\n",
            "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.472973\n",
            "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.844555\n",
            "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.833147\n",
            "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.813649\n",
            "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.824367\n",
            "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.804972\n",
            "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.890072\n",
            "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.574533\n",
            "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.513217\n",
            "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.631630\n",
            "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.704224\n",
            "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.763939\n",
            "Training time: 0m 15s\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 49/10000 (0%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 102/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 150/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 196/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 247/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 290/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 342/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 386/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 434/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 483/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 531/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 582/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 628/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 676/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 720/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 772/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 817/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 861/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 909/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 952/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 997/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1047/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1096/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1140/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1192/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1234/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1281/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1323/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1372/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1419/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1464/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1507/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1550/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1600/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1649/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1697/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1748/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1791/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1845/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1887/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1927/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1971/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2017/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2060/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2112/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2158/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2200/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2254/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2291/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2341/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2398/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2446/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2497/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2545/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2592/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2637/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2686/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2737/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2784/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2820/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2869/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2912/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2960/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3008/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3060/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3109/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3154/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3199/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3246/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3292/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3340/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3390/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3441/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3490/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3541/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3587/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3633/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3684/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3739/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3792/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3841/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3885/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3937/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3986/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4040/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4092/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4146/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4188/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4240/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4288/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4339/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4384/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4434/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4487/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4535/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4588/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4638/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4691/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4741/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4789/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4840/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4888/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4933/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4980/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5032/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5081/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5130/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5176/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5225/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5275/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5328/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5379/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5430/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5477/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5528/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5580/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5624/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5674/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5726/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5773/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5826/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5878/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5921/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5970/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6016/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6068/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6119/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6166/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6217/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6266/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6316/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6364/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6410/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6462/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6516/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6563/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6616/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6668/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6717/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6770/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6819/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6869/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6921/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6971/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7020/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7070/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7122/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7173/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7222/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7270/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7317/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7363/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7408/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7456/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7503/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7557/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7569/10000 (76%)\n",
            "Testing time: 0m 16s\n",
            "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.834024\n",
            "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.625911\n",
            "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.809734\n",
            "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.581316\n",
            "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.701715\n",
            "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.652358\n",
            "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.790023\n",
            "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.834863\n",
            "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.620392\n",
            "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.467617\n",
            "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.560125\n",
            "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.720706\n",
            "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.650081\n",
            "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.544132\n",
            "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.673033\n",
            "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.845063\n",
            "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.812035\n",
            "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.654525\n",
            "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.742494\n",
            "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.765246\n",
            "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.730056\n",
            "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.875665\n",
            "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.554176\n",
            "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.950565\n",
            "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.732521\n",
            "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.660379\n",
            "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.517590\n",
            "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.746519\n",
            "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.769323\n",
            "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.571419\n",
            "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.663530\n",
            "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.705812\n",
            "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.749811\n",
            "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.924991\n",
            "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.850586\n",
            "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.841507\n",
            "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.759022\n",
            "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.818226\n",
            "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.564300\n",
            "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.933302\n",
            "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.824806\n",
            "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.734773\n",
            "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.718206\n",
            "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.559000\n",
            "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.854878\n",
            "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.634561\n",
            "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.589202\n",
            "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.736264\n",
            "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.535413\n",
            "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.575570\n",
            "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.822677\n",
            "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.727597\n",
            "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.681411\n",
            "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.765072\n",
            "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.851435\n",
            "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.627855\n",
            "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.695117\n",
            "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.645554\n",
            "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.904833\n",
            "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.686288\n",
            "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.955195\n",
            "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.693620\n",
            "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.592915\n",
            "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.533329\n",
            "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.464898\n",
            "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.557675\n",
            "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.772157\n",
            "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.887165\n",
            "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.402458\n",
            "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.756276\n",
            "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.625952\n",
            "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.674812\n",
            "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.688594\n",
            "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.618795\n",
            "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.580161\n",
            "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.762044\n",
            "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.646674\n",
            "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.417600\n",
            "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.688934\n",
            "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.695197\n",
            "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.508113\n",
            "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.771536\n",
            "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.731199\n",
            "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.777519\n",
            "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.806573\n",
            "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.711684\n",
            "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.621947\n",
            "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.814657\n",
            "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.670237\n",
            "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.685330\n",
            "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.703821\n",
            "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.822876\n",
            "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.522903\n",
            "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.787891\n",
            "Training time: 0m 15s\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 49/10000 (0%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 102/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 150/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 197/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 248/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 290/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 341/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 387/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 433/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 482/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 531/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 582/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 629/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 679/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 724/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 779/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 823/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 867/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 914/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 957/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1001/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1052/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1101/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1144/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1198/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1239/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1287/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1331/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1380/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1428/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1473/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1517/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1561/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1610/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1660/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1707/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1757/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1806/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1860/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1902/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1942/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1987/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2038/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2080/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2132/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2178/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2221/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2276/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2315/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2364/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2422/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2470/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2522/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2572/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2620/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2667/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2719/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2770/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2816/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2855/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2903/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2945/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2993/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3042/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3093/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3140/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3187/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3233/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3279/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3328/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3374/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3424/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3474/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3522/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3573/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3619/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3665/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3715/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3767/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3819/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3868/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3913/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3965/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4014/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4069/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4121/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4175/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4216/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4265/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4311/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4362/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4406/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4454/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4506/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4553/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4605/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4655/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4708/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4758/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4806/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4858/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4906/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4951/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4998/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5052/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5103/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5151/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5197/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5247/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5297/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5349/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5399/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5450/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5497/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5549/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5601/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5643/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5694/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5745/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5792/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5845/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5898/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5946/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5997/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6044/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6095/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6147/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6195/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6247/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6297/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6347/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6395/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6445/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6497/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6551/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6598/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6651/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6703/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6752/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6805/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6854/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6903/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6956/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7005/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7055/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7106/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7158/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7208/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7256/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7306/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7354/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7403/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7448/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7496/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7542/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7596/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7608/10000 (76%)\n",
            "Testing time: 0m 17s\n",
            "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.551551\n",
            "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.854358\n",
            "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.709309\n",
            "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.592698\n",
            "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.538802\n",
            "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.698915\n",
            "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.578354\n",
            "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.575545\n",
            "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.622304\n",
            "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.608233\n",
            "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.600020\n",
            "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.777071\n",
            "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.573856\n",
            "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.790954\n",
            "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.773848\n",
            "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.329921\n",
            "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.503529\n",
            "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.489985\n",
            "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.705565\n",
            "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.526639\n",
            "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.638382\n",
            "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.431983\n",
            "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.532880\n",
            "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.421042\n",
            "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.600517\n",
            "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.583274\n",
            "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.629401\n",
            "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.350908\n",
            "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.365182\n",
            "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.549932\n",
            "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.443899\n",
            "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.382303\n",
            "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.366053\n",
            "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.368094\n",
            "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.528300\n",
            "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.201615\n",
            "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.658304\n",
            "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.505051\n",
            "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.433140\n",
            "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.529942\n",
            "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.526720\n",
            "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.340519\n",
            "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.288187\n",
            "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.507781\n",
            "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.448683\n",
            "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.342164\n",
            "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.243530\n",
            "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.662562\n",
            "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.569073\n",
            "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.543253\n",
            "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.830144\n",
            "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.311308\n",
            "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.376050\n",
            "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.356264\n",
            "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.580420\n",
            "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.814485\n",
            "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.491857\n",
            "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.543186\n",
            "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.523644\n",
            "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.387982\n",
            "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.384889\n",
            "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.314885\n",
            "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.438590\n",
            "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.643972\n",
            "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.521501\n",
            "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.440024\n",
            "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.439573\n",
            "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.360168\n",
            "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.533065\n",
            "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.622888\n",
            "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.376401\n",
            "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.366202\n",
            "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.403296\n",
            "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.288246\n",
            "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.351534\n",
            "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.304037\n",
            "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.405068\n",
            "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.323983\n",
            "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.707967\n",
            "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.526450\n",
            "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.519821\n",
            "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.620074\n",
            "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.321836\n",
            "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.462560\n",
            "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.353763\n",
            "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.246660\n",
            "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.519510\n",
            "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.576782\n",
            "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.647860\n",
            "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.755037\n",
            "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.359803\n",
            "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.467612\n",
            "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.380271\n",
            "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.273994\n",
            "Training time: 0m 15s\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 52/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 108/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 159/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 212/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 267/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 315/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 372/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 426/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 479/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 533/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 584/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 641/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 697/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 756/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 808/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 865/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 916/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 965/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1015/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1063/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1108/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1164/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1215/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1268/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1324/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1376/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1428/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1477/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1534/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1584/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1637/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1683/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1734/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1788/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1840/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1891/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1948/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2002/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2058/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2105/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2151/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2205/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2260/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2311/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2367/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2418/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2466/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2526/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2575/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2627/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2686/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2744/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2798/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2855/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2909/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2960/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3012/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3065/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3117/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3161/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3209/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3255/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3309/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3361/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3418/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3470/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3520/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3568/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3619/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3672/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3729/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3780/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3839/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3892/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3948/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3998/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4050/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4104/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4158/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4210/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4264/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4317/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4376/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4432/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4490/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4548/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4606/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4657/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4706/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4759/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4818/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4867/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4919/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 4974/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5023/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5076/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5127/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5184/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5241/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5295/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5352/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5406/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5456/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5506/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5567/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5623/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5675/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5728/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5786/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5841/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5898/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5957/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6017/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6073/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6129/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6187/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6237/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6293/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6347/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6399/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6458/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6516/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6564/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6613/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6664/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6720/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6773/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6828/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6887/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6941/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6994/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7050/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7107/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7163/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7222/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7275/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7333/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7390/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7446/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7506/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 7559/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7614/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7671/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7724/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7783/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7839/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7896/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7956/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8009/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8066/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8120/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8175/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8225/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8278/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8332/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8388/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8400/10000 (84%)\n",
            "Testing time: 0m 16s\n",
            "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.590803\n",
            "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.282394\n",
            "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.444197\n",
            "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.221763\n",
            "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.432287\n",
            "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.638085\n",
            "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.282544\n",
            "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.512079\n",
            "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.510860\n",
            "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.334820\n",
            "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.547943\n",
            "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.689461\n",
            "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.507496\n",
            "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.444539\n",
            "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.412797\n",
            "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.509284\n",
            "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.337776\n",
            "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.441855\n",
            "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.317001\n",
            "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.462987\n",
            "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.556858\n",
            "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.434359\n",
            "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.344407\n",
            "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.379756\n",
            "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.380950\n",
            "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.198043\n",
            "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.261164\n",
            "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.324029\n",
            "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.283429\n",
            "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.276690\n",
            "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.400004\n",
            "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.397256\n",
            "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.403837\n",
            "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.537780\n",
            "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.264112\n",
            "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.444138\n",
            "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.308209\n",
            "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.393232\n",
            "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.289847\n",
            "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.299872\n",
            "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.366134\n",
            "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.538649\n",
            "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.375039\n",
            "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.483143\n",
            "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.211202\n",
            "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.393023\n",
            "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.380575\n",
            "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.133046\n",
            "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.587652\n",
            "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.308532\n",
            "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.392101\n",
            "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.133254\n",
            "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.386634\n",
            "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.316788\n",
            "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.545273\n",
            "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.413305\n",
            "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.235559\n",
            "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.198628\n",
            "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.541321\n",
            "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.300745\n",
            "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.221039\n",
            "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.550704\n",
            "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.457707\n",
            "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.480075\n",
            "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.282353\n",
            "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.363282\n",
            "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.218962\n",
            "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.281259\n",
            "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.573432\n",
            "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.392608\n",
            "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.393358\n",
            "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.237821\n",
            "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.272569\n",
            "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.756293\n",
            "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.325203\n",
            "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.565401\n",
            "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.242287\n",
            "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.338116\n",
            "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.511509\n",
            "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.316187\n",
            "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.304786\n",
            "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.441971\n",
            "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.485543\n",
            "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.390128\n",
            "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.316200\n",
            "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.345811\n",
            "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.529373\n",
            "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.315375\n",
            "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.434240\n",
            "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.475443\n",
            "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.280490\n",
            "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.479934\n",
            "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.389482\n",
            "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.368262\n",
            "Training time: 0m 15s\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 56/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 116/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 168/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 223/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 278/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 329/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 387/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 442/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 500/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 557/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 612/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 667/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 724/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 781/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 835/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 892/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 946/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 999/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1050/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1100/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1151/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1207/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1260/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1313/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1371/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1425/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1479/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1533/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1591/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1644/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1698/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1748/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1801/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1854/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1908/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1964/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2024/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2077/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2133/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2185/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2234/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2290/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2349/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2401/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2458/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2509/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2560/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2619/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2670/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2726/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2787/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2846/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2902/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2958/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3015/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3068/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3121/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3177/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3230/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3276/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3328/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3378/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3436/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3489/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3548/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3602/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3655/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3704/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3757/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3813/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3872/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3927/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3986/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4040/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4096/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4148/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4203/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4258/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4318/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4372/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4428/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4483/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4543/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4600/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4658/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4715/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4776/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4828/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4883/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4936/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4995/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5045/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5099/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5154/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5206/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5264/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5317/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5374/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5432/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5488/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5547/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5602/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5652/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5707/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5769/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5828/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5885/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5940/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5998/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6055/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6115/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6173/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6234/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6291/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6348/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6406/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6458/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6516/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6573/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6628/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6688/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6746/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6794/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6849/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6903/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6961/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7017/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7073/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7133/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7192/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7250/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7306/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7362/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7417/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7477/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7531/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7589/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7647/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7704/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7765/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7822/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7879/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7937/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7996/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8055/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8110/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8167/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8227/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8283/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8341/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8395/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8449/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8500/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8557/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8613/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8672/10000 (87%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8686/10000 (87%)\n",
            "Testing time: 0m 16s\n",
            "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.355227\n",
            "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.412952\n",
            "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.409944\n",
            "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.408937\n",
            "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.381115\n",
            "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.431203\n",
            "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.391980\n",
            "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.439278\n",
            "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.351222\n",
            "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.351001\n",
            "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.314269\n",
            "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.616590\n",
            "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.353267\n",
            "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.370232\n",
            "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.447440\n",
            "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.288981\n",
            "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.185299\n",
            "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.584697\n",
            "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.465588\n",
            "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.329738\n",
            "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.267886\n",
            "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.352152\n",
            "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.275873\n",
            "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.181613\n",
            "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.408807\n",
            "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.268010\n",
            "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.488311\n",
            "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.400785\n",
            "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.432848\n",
            "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.488093\n",
            "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.410482\n",
            "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.339176\n",
            "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.392851\n",
            "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.404340\n",
            "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.383009\n",
            "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.374769\n",
            "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.225958\n",
            "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.291496\n",
            "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.309339\n",
            "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.500143\n",
            "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.411170\n",
            "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.445774\n",
            "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.429669\n",
            "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.388023\n",
            "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.513585\n",
            "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.353547\n",
            "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.555111\n",
            "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.317139\n",
            "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.481677\n",
            "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.514206\n",
            "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.348877\n",
            "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.355501\n",
            "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.428701\n",
            "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.255450\n",
            "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.517775\n",
            "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.358722\n",
            "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.266919\n",
            "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.402415\n",
            "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.287338\n",
            "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.235295\n",
            "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.147232\n",
            "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.707088\n",
            "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.529143\n",
            "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.353625\n",
            "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.378212\n",
            "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.578699\n",
            "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.377212\n",
            "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.412697\n",
            "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.549226\n",
            "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.424851\n",
            "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.404507\n",
            "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.359137\n",
            "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.584199\n",
            "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.596981\n",
            "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.331009\n",
            "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.501107\n",
            "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.253100\n",
            "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.454779\n",
            "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.399407\n",
            "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.241600\n",
            "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.339156\n",
            "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.478295\n",
            "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.306763\n",
            "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.261264\n",
            "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.148503\n",
            "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.578011\n",
            "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.411013\n",
            "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.239913\n",
            "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.328088\n",
            "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.437830\n",
            "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.200803\n",
            "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.168204\n",
            "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.249256\n",
            "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.177706\n",
            "Training time: 0m 15s\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 56/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 116/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 168/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 223/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 280/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 329/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 385/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 440/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 499/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 557/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 613/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 668/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 726/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 783/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 838/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 896/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 948/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1000/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1056/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1106/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1159/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1216/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1272/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1325/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1383/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1435/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1488/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1543/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1601/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1653/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1707/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1758/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1811/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1866/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1920/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1975/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2035/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2089/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2146/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2199/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2249/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2305/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2363/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2416/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2473/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2526/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2578/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2636/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2688/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2746/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2808/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2866/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2923/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2982/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3039/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3094/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3147/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3202/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3256/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3304/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3357/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3409/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3466/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3517/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3576/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3630/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3684/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3735/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3789/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3843/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3901/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3956/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4016/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4072/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4130/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4185/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4239/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4294/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4355/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4412/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4469/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4524/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4582/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4639/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4697/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4754/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4815/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4868/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4923/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4977/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5036/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5085/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5139/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5194/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5246/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5304/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5360/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5417/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5475/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5533/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5593/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5648/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5701/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5756/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5818/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5878/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5935/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5990/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6047/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6104/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6163/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6221/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6282/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6339/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6397/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6455/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6508/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6566/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6624/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6679/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6739/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6797/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6847/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6903/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6957/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7015/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7073/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7129/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7189/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7249/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7308/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7364/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7422/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7477/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7537/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7591/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7649/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7707/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7764/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7825/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7883/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7942/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8000/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8059/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8118/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8174/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8231/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8291/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8347/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8405/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8460/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8515/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8567/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8623/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8678/10000 (87%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8736/10000 (87%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8750/10000 (88%)\n",
            "Testing time: 0m 16s\n",
            "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.324960\n",
            "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.245512\n",
            "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.357723\n",
            "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.336119\n",
            "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.241923\n",
            "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.195155\n",
            "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.469552\n",
            "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.316558\n",
            "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.314593\n",
            "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.469554\n",
            "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.428496\n",
            "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.573962\n",
            "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.316790\n",
            "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.326859\n",
            "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.252620\n",
            "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.507778\n",
            "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.197191\n",
            "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.350091\n",
            "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.423569\n",
            "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.275137\n",
            "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.117023\n",
            "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.271795\n",
            "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.476860\n",
            "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.468200\n",
            "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.395412\n",
            "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.242829\n",
            "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.376600\n",
            "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.310722\n",
            "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.403570\n",
            "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.296919\n",
            "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.438358\n",
            "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.236976\n",
            "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.302403\n",
            "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.351336\n",
            "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.271052\n",
            "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.400405\n",
            "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.538994\n",
            "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.266400\n",
            "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.334108\n",
            "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.316833\n",
            "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.303766\n",
            "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.284266\n",
            "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.209020\n",
            "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.490688\n",
            "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.342843\n",
            "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.312505\n",
            "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.506447\n",
            "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.222210\n",
            "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.348204\n",
            "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.328481\n",
            "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.307762\n",
            "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.364217\n",
            "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.266126\n",
            "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.222681\n",
            "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.423802\n",
            "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.476504\n",
            "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.380461\n",
            "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.419165\n",
            "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.284384\n",
            "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.182015\n",
            "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.442022\n",
            "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.222802\n",
            "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.462734\n",
            "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.469143\n",
            "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.221784\n",
            "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.189441\n",
            "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.235531\n",
            "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.284389\n",
            "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.225221\n",
            "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.400483\n",
            "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.429764\n",
            "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.349326\n",
            "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.376505\n",
            "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.281471\n",
            "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.295005\n",
            "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.381279\n",
            "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.325464\n",
            "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.255716\n",
            "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.581320\n",
            "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.295763\n",
            "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.365011\n",
            "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.158119\n",
            "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.358333\n",
            "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.296962\n",
            "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.421434\n",
            "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.477035\n",
            "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.328967\n",
            "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.267644\n",
            "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.400976\n",
            "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.340560\n",
            "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.548887\n",
            "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.323766\n",
            "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.232900\n",
            "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.418963\n",
            "Training time: 0m 15s\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 56/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 117/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 169/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 224/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 282/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 332/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 389/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 444/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 503/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 559/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 613/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 671/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 728/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 787/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 844/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 901/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 955/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1008/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1064/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1115/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1166/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1223/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1279/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1332/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1390/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1445/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1499/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1554/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1612/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1665/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1719/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1769/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1821/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1877/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1932/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1988/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2048/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2102/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2159/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2211/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2261/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2317/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2375/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2427/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2484/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2536/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2588/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2648/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2699/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2757/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2820/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2877/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2934/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2992/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3048/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3103/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3157/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3212/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3267/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3314/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3367/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3418/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3475/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3527/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3586/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3642/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3694/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3742/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3796/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3849/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3909/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3965/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4024/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4078/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4137/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4193/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4247/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4302/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4363/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4420/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4478/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4533/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4593/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4650/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4708/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4765/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4826/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4878/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4933/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4987/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5046/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5097/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5151/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5206/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5257/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5314/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5368/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5425/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5483/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5541/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5601/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5656/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5707/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5762/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5824/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5881/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5938/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5993/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6051/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6108/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6168/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6227/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6288/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6346/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6404/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6462/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6515/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6573/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6630/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6685/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6745/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6803/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6853/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6909/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6965/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7023/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7081/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7137/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7196/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7254/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7313/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7369/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7424/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7481/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7541/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7595/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7653/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7711/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7768/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7829/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7886/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7944/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8002/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8061/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8120/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8175/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8232/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8292/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8348/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8405/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8458/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8513/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8565/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8623/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8680/10000 (87%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8740/10000 (87%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8754/10000 (88%)\n",
            "Testing time: 0m 16s\n",
            "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.380228\n",
            "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.518242\n",
            "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.226258\n",
            "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.295998\n",
            "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.216203\n",
            "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.301151\n",
            "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.345218\n",
            "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.115530\n",
            "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.311467\n",
            "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.301888\n",
            "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.153838\n",
            "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.443686\n",
            "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.410065\n",
            "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.305916\n",
            "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.297447\n",
            "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.596520\n",
            "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.207162\n",
            "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.327243\n",
            "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.297297\n",
            "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.221609\n",
            "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.301766\n",
            "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.314133\n",
            "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.363272\n",
            "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.287335\n",
            "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.490389\n",
            "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.169617\n",
            "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.177874\n",
            "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.313924\n",
            "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.456265\n",
            "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.225032\n",
            "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.130208\n",
            "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.394765\n",
            "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.202912\n",
            "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.419189\n",
            "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.316858\n",
            "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.549211\n",
            "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.302378\n",
            "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.351494\n",
            "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.272776\n",
            "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.253599\n",
            "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.243603\n",
            "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.289303\n",
            "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.231557\n",
            "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.196076\n",
            "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.316519\n",
            "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.157387\n",
            "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.226467\n",
            "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.411771\n",
            "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.370817\n",
            "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.190339\n",
            "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.359538\n",
            "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.457075\n",
            "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.199855\n",
            "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.543523\n",
            "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.324483\n",
            "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.573979\n",
            "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.372413\n",
            "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.249365\n",
            "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.391296\n",
            "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.298210\n",
            "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.399363\n",
            "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.262496\n",
            "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.365256\n",
            "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.375103\n",
            "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.452646\n",
            "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.438540\n",
            "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.393962\n",
            "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.220999\n",
            "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.614975\n",
            "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.307170\n",
            "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.251749\n",
            "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.316673\n",
            "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.294867\n",
            "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.353040\n",
            "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.484205\n",
            "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.370724\n",
            "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.247544\n",
            "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.249910\n",
            "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.130559\n",
            "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.203920\n",
            "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.261864\n",
            "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.327437\n",
            "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.310950\n",
            "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.148971\n",
            "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.299397\n",
            "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.185700\n",
            "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.320805\n",
            "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.318631\n",
            "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.092577\n",
            "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.397767\n",
            "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.202794\n",
            "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.407281\n",
            "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.185320\n",
            "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.337799\n",
            "Training time: 0m 15s\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 56/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 117/10000 (1%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 169/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 224/10000 (2%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 281/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 332/10000 (3%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 389/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 444/10000 (4%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 503/10000 (5%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 560/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 614/10000 (6%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 671/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 727/10000 (7%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 786/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 844/10000 (8%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 901/10000 (9%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 956/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1009/10000 (10%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1065/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1116/10000 (11%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1167/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1224/10000 (12%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1279/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1331/10000 (13%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1389/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1443/10000 (14%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1498/10000 (15%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1553/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1611/10000 (16%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1664/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1718/10000 (17%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 1767/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1819/10000 (18%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1875/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1930/10000 (19%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 1985/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2045/10000 (20%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2102/10000 (21%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2158/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2211/10000 (22%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2261/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2316/10000 (23%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2375/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2429/10000 (24%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2486/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2538/10000 (25%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2590/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2649/10000 (26%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 2701/10000 (27%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2759/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2820/10000 (28%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2878/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2935/10000 (29%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 2994/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3050/10000 (30%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3103/10000 (31%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3157/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3213/10000 (32%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3267/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3315/10000 (33%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3369/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3421/10000 (34%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3475/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3527/10000 (35%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3586/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3643/10000 (36%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3696/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 3747/10000 (37%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3800/10000 (38%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3855/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3915/10000 (39%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 3970/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4030/10000 (40%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4085/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4143/10000 (41%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4198/10000 (42%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4252/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4308/10000 (43%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4367/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4424/10000 (44%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4482/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4537/10000 (45%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4597/10000 (46%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4654/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4711/10000 (47%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4768/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4829/10000 (48%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4883/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4938/10000 (49%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 4992/10000 (50%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5051/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5103/10000 (51%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5158/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 5213/10000 (52%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5265/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5320/10000 (53%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5373/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5430/10000 (54%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5488/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5546/10000 (55%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5605/10000 (56%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5660/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5714/10000 (57%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5770/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5831/10000 (58%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5887/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5945/10000 (59%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 5999/10000 (60%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6058/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6115/10000 (61%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6175/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6234/10000 (62%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6295/10000 (63%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6352/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6409/10000 (64%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6467/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6519/10000 (65%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6577/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6635/10000 (66%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6689/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6749/10000 (67%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6807/10000 (68%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 6860/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6918/10000 (69%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 6972/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7029/10000 (70%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7085/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7141/10000 (71%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7200/10000 (72%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7258/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7316/10000 (73%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7372/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7428/10000 (74%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7485/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7545/10000 (75%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7599/10000 (76%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7657/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7714/10000 (77%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7771/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7832/10000 (78%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7889/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 7948/10000 (79%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8006/10000 (80%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8064/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8123/10000 (81%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8179/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8236/10000 (82%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8296/10000 (83%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8352/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8409/10000 (84%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8463/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8518/10000 (85%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0001, Accuracy: 8570/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8628/10000 (86%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8684/10000 (87%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8744/10000 (87%)\n",
            "===========================\n",
            "Test set: Average loss: 0.0000, Accuracy: 8758/10000 (88%)\n",
            "Testing time: 0m 16s\n",
            "Total Time: 2m 26s\n",
            "Model was trained on cpu!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}